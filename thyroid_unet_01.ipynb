{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-HVpa61a8yXx"
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 435,
     "status": "ok",
     "timestamp": 1554031342202,
     "user": {
      "displayName": "Soo Hyon Lee",
      "photoUrl": "",
      "userId": "17381840632197617822"
     },
     "user_tz": 240
    },
    "id": "i79D4aE-Ixf7",
    "outputId": "afa2ef49-d3ab-4c73-aee2-7776ca71965e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1359,
     "status": "ok",
     "timestamp": 1554034678320,
     "user": {
      "displayName": "Soo Hyon Lee",
      "photoUrl": "",
      "userId": "17381840632197617822"
     },
     "user_tz": 240
    },
    "id": "YTBB92Wn8yX7",
    "outputId": "00ba0c38-8c57-41d8-d224-467a4f2e4bb5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.losses import *\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "import pdb\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.losses import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21361,
     "status": "ok",
     "timestamp": 1554031337247,
     "user": {
      "displayName": "Soo Hyon Lee",
      "photoUrl": "",
      "userId": "17381840632197617822"
     },
     "user_tz": 240
    },
    "id": "XwzSmhfbe5sT",
    "outputId": "ab70bb19-d3a7-458b-a416-aaaf3533493a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "#Mount Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z8vmysfr8yYH"
   },
   "outputs": [],
   "source": [
    "# Directories\n",
    "train_root = '/content/drive/My Drive/Colab Notebooks/data/train'\n",
    "valid_root = '/content/drive/My Drive/Colab Notebooks/data/test'\n",
    "test_root = '/content/drive/My Drive/Colab Notebooks/data/test'\n",
    "gt_root = '/content/drive/My Drive/Colab Notebooks/data/test/label'\n",
    "test_code_root = '/content/drive/My Drive/Colab Notebooks/test_code'\n",
    "output_root = '/content/drive/My Drive/Colab Notebooks/output/outputs'\n",
    "train_ckpt_path = '/content/drive/My Drive/Colab Notebooks/output/unet.hdf5'\n",
    "\n",
    "\n",
    "# Variables\n",
    "resume = False\n",
    "input_size = (240,240,1)\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "epoch = 20\n",
    "lr = 0.0001\n",
    "train_batch_size = 33\n",
    "test_batch_size = 88\n",
    "input_size = (240,240,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cKNJ7XFwK8eE"
   },
   "outputs": [],
   "source": [
    "\n",
    "# label = cv2.imread(os.path.join(test_root,'label/000.jpg')) \n",
    "# print(label.shape)\n",
    "# label = np.expand_dims(label, axis=2)*255\n",
    "# print(label.shape)\n",
    "# zeros = np.zeros(label.shape)\n",
    "# label = np.concatenate((zeros,zeros,label), axis=2)  \n",
    "# print(label.shape)\n",
    "# gt_img = cv2.imread(os.path.join(gt_root, '000.png'))\n",
    "# print(gt_img)\n",
    "# gt_img = gt_img+label\n",
    "# gt_img = (gt_img/(gt_img.max()+1e-6))*255\n",
    "# cv2.imwrite(gt_root, gt_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NR3cbW0j8yYP"
   },
   "outputs": [],
   "source": [
    "\n",
    "def bce_loss(y_true, y_pred):\n",
    "    ''' Binary Cross Entropy\n",
    "\n",
    "    Args:\n",
    "        y_true (np.array): prediction\n",
    "        y_pred (np.array): ground-truth\n",
    "    '''\n",
    "    return binary_crossentropy(y_true, y_pred)\n",
    "  \n",
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_numpy(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = np.ndarray.flatten(y_true)\n",
    "    y_pred_f = np.ndarray.flatten(y_pred)\n",
    "    intersection = np.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)\n",
    "\n",
    "def iou_score(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (1. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "def dice_coef_log_loss(y_true, y_pred):\n",
    "    return -K.log(dice_coef(y_true, y_pred))\n",
    "\n",
    "def iou_score_loss(y_true, y_pred):\n",
    "    return -iou_score(y_true, y_pred)\n",
    "\n",
    "def plt_img(img=None, img_path=None, save_path=None):\n",
    "    ''' Plot Image using given image or image_path\n",
    "\n",
    "    Args:\n",
    "        img         (np.array)  : image to plot\n",
    "        img_path    (str)       : image path to plot\n",
    "        save_path   (str)       : save directory for plotted image\n",
    "    '''\n",
    "    if isinstance(save_path, type(None)):\n",
    "        save_path = './plt_img.jpg'\n",
    "\n",
    "    if not(isinstance(img, type(None))):\n",
    "        #cv2.imwrite(save_path,img)\n",
    "        plt.rcParams['figure.figsize'] = [10, 30]\n",
    "        plt.imshow(img, clim=(0, 255))\n",
    "        #plt.imshow(np.rot90(img, -1), clim=(0, 255))\n",
    "\n",
    "    if not(isinstance(img_path, type(None))):\n",
    "        img = cv2.imread(img_path)\n",
    "        #cv2.imwrite(save_path, img)\n",
    "        plt.imshow(img, clim=(0, 255))\n",
    "        #plt.imshow(np.rot90(img, -1), clim=(0, 255))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_data(image, label):\n",
    "    ''' Adjust images and labels for network inputs\n",
    "\n",
    "    Args:\n",
    "        image   (np.array):   Augmented images\n",
    "        label   (np.array):   Augmented labels\n",
    "    '''\n",
    "    image = image[0] / 255\n",
    "    label = label[0]/255\n",
    "    label[label>0.5] =1\n",
    "    label[label<=0.5]=0\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def dataset(mode, data_root, batch_size,\n",
    "            image_color_mode = \"grayscale\",\n",
    "            label_color_mode = \"grayscale\",\n",
    "            target_size = (240,240)):\n",
    "\n",
    "    ''' Prepare dataset ( pre-processing + augmentation(optional) )\n",
    "\n",
    "    Args:\n",
    "        args (argparse):          Arguments parsered in command-lind\n",
    "        image_color_mode (str):   Image color Mode Flag\n",
    "        label_color_mode (str):   Label color Mode Flag\n",
    "        target_size (tuple):      Target Size\n",
    "    '''\n",
    "    if mode == 'train':\n",
    "        shuffle=True\n",
    "        # Data Augmentation (image)\n",
    "        image_datagen = ImageDataGenerator(rotation_range=15,\n",
    "                                           horizontal_flip=True,\n",
    "                                           vertical_flip=False,\n",
    "                                           width_shift_range=0.1,\n",
    "                                           height_shift_range=0.1,\n",
    "                                           shear_range=0.2,\n",
    "                                           zoom_range=0.1)\n",
    "\n",
    "        # Data Augmentation (label)\n",
    "        label_datagen = ImageDataGenerator(rotation_range=15,\n",
    "                                           horizontal_flip=True,\n",
    "                                           vertical_flip=False,\n",
    "                                           width_shift_range=0.1,\n",
    "                                           height_shift_range=0.1,\n",
    "                                           shear_range=0.2,\n",
    "                                           zoom_range=0.1)\n",
    "\n",
    "        print('Train Set is prepared')\n",
    "\n",
    "    elif mode == 'valid':\n",
    "        shuffle=False\n",
    "        image_datagen = ImageDataGenerator()\n",
    "        label_datagen = ImageDataGenerator()\n",
    "\n",
    "        print('Validation Set is prepared')\n",
    "\n",
    "    elif mode == 'test':\n",
    "        shuffle=False\n",
    "        image_datagen = ImageDataGenerator()\n",
    "        label_datagen = ImageDataGenerator()\n",
    "\n",
    "        print('Test Set is prepared')\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Dataset Mode ERROR')\n",
    "\n",
    "    # Dataloader (image)\n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        data_root,\n",
    "        classes=['image'],\n",
    "        color_mode=image_color_mode,\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        seed=1)\n",
    "\n",
    "   # Dataloader (label)\n",
    "    label_generator = label_datagen.flow_from_directory(\n",
    "        data_root,\n",
    "        classes=['label'],\n",
    "        color_mode=label_color_mode,\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        seed=1)\n",
    "\n",
    "    data_generator = zip(image_generator, label_generator)\n",
    "    for i, (image, label) in enumerate(data_generator):\n",
    "        image, label = adjust_data(image, label)\n",
    "        ##Save augmentated images and labels\n",
    "        #for j in range(image.shape[0]):\n",
    "        #    cv2.imwrite(str(i)+'-'+str(j)+'.jpg', image[j].squeeze()*255)\n",
    "        #    cv2.imwrite(str(i)+'-'+str(j)+'_.jpg', label[j].squeeze()*255)\n",
    "        yield (image, label)\n",
    "\n",
    "\n",
    "def save_result(output, data_root, output_root, gt_root=None):\n",
    "  \n",
    "    ''' Save Prediction results overlapping on original images\n",
    "\n",
    "    Args:\n",
    "        args (argparse):    Arguments parsered in command-lind\n",
    "        output (np.array):  Prediction Results by segementation model\n",
    "        \n",
    "    '''\n",
    "    file_path = []\n",
    "    file_path += glob.glob(os.path.join(data_root, 'image/*.jpg'))\n",
    "    file_path = sorted(file_path)\n",
    "    output = output.squeeze()\n",
    "    final = None\n",
    "    \n",
    "    for i in range(output.shape[0]):\n",
    "        if len(str(i)) == 1:\n",
    "            name = '00'+str(i)\n",
    "        elif len(str(i)) == 2:\n",
    "            name = '0'+str(i)\n",
    "        else:\n",
    "            name = str(i)\n",
    "\n",
    "        save_path = os.path.join(output_root, name+'.jpg')\n",
    "        img = cv2.imread(file_path[i])\n",
    "        pred = (output[i]>0.5).astype(int)\n",
    "        pred = np.expand_dims(pred, axis=2)*255\n",
    "        zeros = np.zeros(pred.shape)\n",
    "        pred = np.concatenate((zeros,zeros,pred), axis=2)\n",
    "        img = img + pred\n",
    "        img = (img/(img.max()+1e-6))*255\n",
    "        cv2.imwrite(save_path, img)\n",
    "\n",
    "        # Print Example of Prediction and Ground-truth\n",
    "        if (i==90 or i==63 or i==82 or i==10):\n",
    "            gt_img = cv2.imread(os.path.join(gt_root, name+'.jpg'))\n",
    "            img = (np.concatenate((img,gt_img),axis=1)).astype(np.uint8)\n",
    "            if isinstance(final, type(None)):\n",
    "                final = img\n",
    "            else:\n",
    "                final = np.concatenate((final, img), axis=0).astype(np.uint8)\n",
    "    \n",
    "    plt_img(img=final, save_path=os.path.join(test_code_root,'results.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7HOnsQtr8yYd"
   },
   "source": [
    "# Model (U-net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1554034767312,
     "user": {
      "displayName": "Soo Hyon Lee",
      "photoUrl": "",
      "userId": "17381840632197617822"
     },
     "user_tz": 240
    },
    "id": "bUjDbyF98yYg",
    "outputId": "2464be1d-0c6a-436e-821a-e092b3dedb02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_1:0\", shape=(?, 240, 240, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(input_size)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 801,
     "status": "ok",
     "timestamp": 1554031367003,
     "user": {
      "displayName": "Soo Hyon Lee",
      "photoUrl": "",
      "userId": "17381840632197617822"
     },
     "user_tz": 240
    },
    "id": "vt2Ugw0A8yY1",
    "outputId": "d5fb43e7-c65e-4eca-e063-3ca12f0451f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Tensor(\"conv2d_1/Relu:0\", shape=(?, 240, 240, 16), dtype=float32)\n",
      "Tensor(\"conv2d_2/Relu:0\", shape=(?, 240, 240, 16), dtype=float32)\n",
      "Tensor(\"max_pooling2d_1/MaxPool:0\", shape=(?, 120, 120, 16), dtype=float32)\n",
      "Tensor(\"conv2d_3/Relu:0\", shape=(?, 120, 120, 32), dtype=float32)\n",
      "Tensor(\"conv2d_4/Relu:0\", shape=(?, 120, 120, 32), dtype=float32)\n",
      "Tensor(\"max_pooling2d_2/MaxPool:0\", shape=(?, 60, 60, 32), dtype=float32)\n",
      "Tensor(\"conv2d_5/Relu:0\", shape=(?, 60, 60, 64), dtype=float32)\n",
      "Tensor(\"conv2d_6/Relu:0\", shape=(?, 60, 60, 64), dtype=float32)\n",
      "Tensor(\"max_pooling2d_3/MaxPool:0\", shape=(?, 30, 30, 64), dtype=float32)\n",
      "Tensor(\"conv2d_7/Relu:0\", shape=(?, 30, 30, 128), dtype=float32)\n",
      "Tensor(\"conv2d_8/Relu:0\", shape=(?, 30, 30, 128), dtype=float32)\n",
      "Tensor(\"max_pooling2d_4/MaxPool:0\", shape=(?, 15, 15, 128), dtype=float32)\n",
      "Tensor(\"conv2d_9/Relu:0\", shape=(?, 15, 15, 256), dtype=float32)\n",
      "Tensor(\"conv2d_10/Relu:0\", shape=(?, 15, 15, 256), dtype=float32)\n",
      "Tensor(\"concatenate_1/concat:0\", shape=(?, 30, 30, 384), dtype=float32)\n",
      "Tensor(\"conv2d_11/Relu:0\", shape=(?, 30, 30, 128), dtype=float32)\n",
      "Tensor(\"conv2d_12/Relu:0\", shape=(?, 30, 30, 128), dtype=float32)\n",
      "Tensor(\"concatenate_2/concat:0\", shape=(?, 60, 60, 128), dtype=float32)\n",
      "Tensor(\"conv2d_13/Relu:0\", shape=(?, 60, 60, 64), dtype=float32)\n",
      "Tensor(\"conv2d_14/Relu:0\", shape=(?, 60, 60, 64), dtype=float32)\n",
      "Tensor(\"concatenate_3/concat:0\", shape=(?, 120, 120, 64), dtype=float32)\n",
      "Tensor(\"conv2d_15/Relu:0\", shape=(?, 120, 120, 32), dtype=float32)\n",
      "Tensor(\"conv2d_16/Relu:0\", shape=(?, 120, 120, 32), dtype=float32)\n",
      "Tensor(\"concatenate_4/concat:0\", shape=(?, 240, 240, 32), dtype=float32)\n",
      "Tensor(\"conv2d_17/Relu:0\", shape=(?, 240, 240, 16), dtype=float32)\n",
      "Tensor(\"conv2d_18/Relu:0\", shape=(?, 240, 240, 16), dtype=float32)\n",
      "Tensor(\"conv2d_19/Sigmoid:0\", shape=(?, 240, 240, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "out1 = Conv2D(16, (3, 3), activation='relu', padding='same')(inputs)\n",
    "print(out1)\n",
    "out1 = Conv2D(16, (3, 3), activation='relu', padding='same')(out1)\n",
    "print(out1)\n",
    "out2 = MaxPooling2D(pool_size=(2, 2))(out1)\n",
    "print(out2)\n",
    "out2 = Conv2D(32, (3, 3), activation='relu', padding='same')(out2)\n",
    "print(out2)\n",
    "out2 = Conv2D(32, (3, 3), activation='relu', padding='same')(out2)\n",
    "print(out2)\n",
    "out3 = MaxPooling2D(pool_size=(2, 2))(out2)\n",
    "print(out3)\n",
    "out3 = Conv2D(64, (3, 3), activation='relu', padding='same')(out3)\n",
    "print(out3)\n",
    "out3 = Conv2D(64, (3, 3), activation='relu', padding='same')(out3)\n",
    "print(out3)\n",
    "out4 = MaxPooling2D(pool_size=(2, 2))(out3)\n",
    "print(out4)\n",
    "out4 = Conv2D(128, (3, 3), activation='relu', padding='same')(out4)\n",
    "print(out4)\n",
    "out4 = Conv2D(128, (3, 3), activation='relu', padding='same')(out4)\n",
    "print(out4)\n",
    "out5 = MaxPooling2D(pool_size=(2, 2))(out4)\n",
    "print(out5)\n",
    "out5 = Conv2D(256, (3, 3), activation='relu', padding='same')(out5)\n",
    "print(out5)\n",
    "out5 = Conv2D(256, (3, 3), activation='relu', padding='same')(out5)\n",
    "print(out5)\n",
    "out4 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(out5),out4], axis=3)\n",
    "print(out4)\n",
    "out4 = Conv2D(128, (3, 3), activation='relu', padding='same')(out4)\n",
    "print(out4)\n",
    "out4 = Conv2D(128, (3, 3), activation='relu', padding='same')(out4)\n",
    "print(out4)\n",
    "out3 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(out4),out3], axis=3)\n",
    "print(out3)\n",
    "out3 = Conv2D(64, (3, 3), activation='relu', padding='same')(out3)\n",
    "print(out3)\n",
    "out3 = Conv2D(64, (3, 3), activation='relu', padding='same')(out3)\n",
    "print(out3)\n",
    "out2 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2),padding='same')(out3),out2], axis=3)\n",
    "print(out2)\n",
    "out2 = Conv2D(32, (3, 3), activation='relu', padding='same')(out2)\n",
    "print(out2)\n",
    "out2 = Conv2D(32, (3, 3), activation='relu', padding='same')(out2)\n",
    "print(out2)\n",
    "out1 = concatenate([Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(out2),out1], axis=3)\n",
    "print(out1)\n",
    "out1 = Conv2D(16, (3, 3), activation='relu', padding='same')(out1)\n",
    "print(out1)\n",
    "out1 = Conv2D(16, (3, 3), activation='relu', padding='same')(out1)\n",
    "print(out1)\n",
    "out1 = Conv2D(1, (1, 1), activation='sigmoid')(out1)\n",
    "print(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ae9b17BE8ybB"
   },
   "outputs": [],
   "source": [
    "# Optimizier / Loss Init\n",
    "model = Model(inputs=[inputs], outputs=[out1])\n",
    "             \n",
    "model.compile(optimizer=Adam(lr=lr), loss=dice_coef_loss, metrics=[dice_coef,bce_loss,iou_score])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dYZmqdk38ybJ"
   },
   "source": [
    "# Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZYaskQYF8ybW"
   },
   "outputs": [],
   "source": [
    "# Trainset Load\n",
    "trainset = dataset(mode='train', data_root=train_root, batch_size=train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "maLDtt5w8ybe"
   },
   "outputs": [],
   "source": [
    "# Validationset Load\n",
    "validset = dataset(mode='valid', data_root=valid_root, batch_size=train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kqvvtls98ybo"
   },
   "outputs": [],
   "source": [
    "# Model Load\n",
    "model_checkpoint = ModelCheckpoint(train_ckpt_path, monitor='val_loss',\n",
    "                                    verbose=2, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 150
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1323818,
     "status": "ok",
     "timestamp": 1554011451286,
     "user": {
      "displayName": "Soo Hyon Lee",
      "photoUrl": "",
      "userId": "17381840632197617822"
     },
     "user_tz": 240
    },
    "id": "1gW6hyjP8ybu",
    "outputId": "ae537e0e-1246-4f83-a5bb-64f8e101d6c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Validation Set is prepared\n",
      "Train Set is prepared\n",
      "Found 151 images belonging to 1 classes.\n",
      "Found 565 images belonging to 1 classes.\n",
      "Found 151 images belonging to 1 classes.\n",
      "Found 565 images belonging to 1 classes.\n",
      " 16/100 [===>..........................] - ETA: 2:40 - loss: -0.6570 - dice_coef: 0.6570 - bce_loss: 0.6850 - iou_score: 0.3285"
     ]
    }
   ],
   "source": [
    "\n",
    "# Model Train\n",
    "history = model.fit_generator(trainset, steps_per_epoch=100, shuffle=True, epochs=epoch,\n",
    "                    validation_data=validset, validation_steps=30,\n",
    "                    callbacks=[model_checkpoint], workers=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cx3fxTA88ycN"
   },
   "source": [
    "# Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LRuKDQb38ycQ"
   },
   "outputs": [],
   "source": [
    "# Data Load\n",
    "testset = dataset(mode='test', data_root=test_root, batch_size=test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1vA-teKz8ycc"
   },
   "outputs": [],
   "source": [
    "# Model Load\n",
    "model.load_weights(train_ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4467,
     "status": "ok",
     "timestamp": 1554034232617,
     "user": {
      "displayName": "Soo Hyon Lee",
      "photoUrl": "",
      "userId": "17381840632197617822"
     },
     "user_tz": 240
    },
    "id": "R_AZsKYu8ycj",
    "outputId": "340f6b75-ad67-4a5a-91e1-6eedb3f7d676"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set is prepared\n",
      "Found 151 images belonging to 1 classes.\n",
      "Found 151 images belonging to 1 classes.\n",
      "1/1 [==============================] - 4s 4s/step\n"
     ]
    }
   ],
   "source": [
    "# Model Test\n",
    "results = model.predict_generator(testset, steps=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dPsZB-ya8ycs"
   },
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "save_result(results, test_root, output_root, gt_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5_363Rmz8ydH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
